{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проект по детекции эмоций по аудио"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка датасета и проверка классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:\\projects\\Python\\ml\\DAILY_WORK\\project_audio\\dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OAF_angry\n",
      "OAF_disgust\n",
      "OAF_Fear\n",
      "OAF_happy\n",
      "OAF_neutral\n",
      "OAF_Pleasant_surprise\n",
      "OAF_Sad\n",
      "YAF_angry\n",
      "YAF_disgust\n",
      "YAF_fear\n",
      "YAF_happy\n",
      "YAF_neutral\n",
      "YAF_pleasant_surprised\n",
      "YAF_sad\n"
     ]
    }
   ],
   "source": [
    "for files in os.listdir(data_path):\n",
    "    print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Распределение количества данных внутри каждого класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry\n",
      "disgust\n",
      "Fear\n",
      "happy\n",
      "neutral\n",
      "Pleasant_surprise\n",
      "Sad\n",
      "angry\n",
      "disgust\n",
      "fear\n",
      "happy\n",
      "neutral\n",
      "pleasant_surprised\n",
      "sad\n"
     ]
    }
   ],
   "source": [
    "data_amount_info = {}\n",
    "data_duration_info = {}\n",
    "\n",
    "for emotion in os.listdir(data_path):\n",
    "    print(emotion[4:])\n",
    "    emotion_path = os.path.join(data_path, files)\n",
    "    for file in os.listdir(emotion_path):\n",
    "        file_path = os.path.join(emotion_path, file)\n",
    "        if file.endswith(\".wav\"):\n",
    "            duration = librosa.get_duration(path=file_path)  # продолжительность файла\n",
    "            data_duration_info[emotion] = data_duration_info.get(emotion, 0) + duration  # добавляем продолжительность к нужной эмоции\n",
    "\n",
    "            data_amount_info[emotion] = data_amount_info.get(emotion, 0) + 1  # считаем количество файлов\n",
    "        else:\n",
    "            print('Найден файл с некорректным разрешением')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# средняя продолжительность звукового фрагмента данных\n",
    "for emotion in data_duration_info.keys():\n",
    "    data_duration_info[emotion] /= data_amount_info[emotion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OAF_angry': 200,\n",
       " 'OAF_disgust': 200,\n",
       " 'OAF_Fear': 200,\n",
       " 'OAF_happy': 200,\n",
       " 'OAF_neutral': 200,\n",
       " 'OAF_Pleasant_surprise': 200,\n",
       " 'OAF_Sad': 200,\n",
       " 'YAF_angry': 200,\n",
       " 'YAF_disgust': 200,\n",
       " 'YAF_fear': 200,\n",
       " 'YAF_happy': 200,\n",
       " 'YAF_neutral': 200,\n",
       " 'YAF_pleasant_surprised': 200,\n",
       " 'YAF_sad': 200}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_amount_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OAF_angry': 2.2683728598345207,\n",
       " 'OAF_disgust': 2.2683728598345207,\n",
       " 'OAF_Fear': 2.2683728598345207,\n",
       " 'OAF_happy': 2.2683728598345207,\n",
       " 'OAF_neutral': 2.2683728598345207,\n",
       " 'OAF_Pleasant_surprise': 2.2683728598345207,\n",
       " 'OAF_Sad': 2.2683728598345207,\n",
       " 'YAF_angry': 2.2683728598345207,\n",
       " 'YAF_disgust': 2.2683728598345207,\n",
       " 'YAF_fear': 2.2683728598345207,\n",
       " 'YAF_happy': 2.2683728598345207,\n",
       " 'YAF_neutral': 2.2683728598345207,\n",
       " 'YAF_pleasant_surprised': 2.2683728598345207,\n",
       " 'YAF_sad': 2.2683728598345207}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_duration_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В датасете одинаковое количество данных на каждую эмоцию и одинаковая средняя длина записи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Демонстрация случайных записей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_waveplot(data, sr, e, ax):\n",
    "    plt.title('Waveplot for audio with {} emotion'.format(e), size=15)\n",
    "    return librosa.display.waveshow(data, sr=sr, ax=ax)\n",
    "\n",
    "def create_spectrogram(data, sr, e, ax):\n",
    "    X = librosa.stft(data)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    plt.title('Spectrogram for audio with {} emotion'.format(e), size=15)\n",
    "    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz', ax=ax)\n",
    "    plt.colorbar(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_waveplot() missing 1 required positional argument: 'ax'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      6\u001b[0m     data, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(file_path)\n\u001b[1;32m----> 7\u001b[0m     \u001b[43mcreate_waveplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memotion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     create_spectrogram(data, sr, emotion)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: create_waveplot() missing 1 required positional argument: 'ax'"
     ]
    }
   ],
   "source": [
    "for emotion in os.listdir(data_path):\n",
    "    emotion_path = os.path.join(data_path, emotion)\n",
    "    for file in os.listdir(emotion_path):\n",
    "        k = np.randint(0, data_amount_info[emotion])\n",
    "        for _ in range(k): continue  # нужно чтобы брать случайный файл из датасета\n",
    "        file_path = os.path.join(emotion_path, file)\n",
    "        if file.endswith(\".wav\"):\n",
    "            data, sr = librosa.load(file_path)\n",
    "            create_waveplot(data, sr, emotion)\n",
    "            create_spectrogram(data, sr, emotion)\n",
    "            break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попытка построить нейронку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2800 files belonging to 14 classes.\n",
      "Using 2240 files for training.\n",
      "Using 560 files for validation.\n"
     ]
    }
   ],
   "source": [
    "training_set, validation_set = keras.utils.audio_dataset_from_directory(\n",
    "    directory=data_path,\n",
    "    batch_size=16,\n",
    "    validation_split=0.2,\n",
    "    output_sequence_length=16_000,\n",
    "    subset='both',\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OAF_Fear',\n",
       " 'OAF_Pleasant_surprise',\n",
       " 'OAF_Sad',\n",
       " 'OAF_angry',\n",
       " 'OAF_disgust',\n",
       " 'OAF_happy',\n",
       " 'OAF_neutral',\n",
       " 'YAF_angry',\n",
       " 'YAF_disgust',\n",
       " 'YAF_fear',\n",
       " 'YAF_happy',\n",
       " 'YAF_neutral',\n",
       " 'YAF_pleasant_surprised',\n",
       " 'YAF_sad']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = training_set.class_names\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze(audio, labels):\n",
    "    '''перевод звука в формат mono'''\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    return audio, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = training_set.map(squeeze, tf.data.AUTOTUNE)\n",
    "validation_set = validation_set.map(squeeze, tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(waveform): \n",
    "    '''Преобразование данных в спектрограмму'''\n",
    "    # кратковременное преобразование Фурье STFT\n",
    "    spectrogram = tf.signal.stft(waveform, frame_length=255, frame_step=128) \n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    return spectrogram[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram_dataset(dataset):\n",
    "    dataset = dataset.map(lambda x, y: (get_spectrogram(x), y),\n",
    "                          num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = get_spectrogram_dataset(training_set) \n",
    "validation_set = get_spectrogram_dataset(validation_set) \n",
    "  \n",
    "val_set = validation_set.take(validation_set.cardinality() // 2) \n",
    "test_set = validation_set.skip(validation_set.cardinality() // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (124, 129, 1)\n"
     ]
    }
   ],
   "source": [
    "input_shape = next(iter(train_set))[0][0].shape \n",
    "print(\"Input shape:\", input_shape) \n",
    "num_labels = len(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([ \n",
    "        tf.keras.layers.Input(shape=input_shape), \n",
    "\n",
    "        tf.keras.layers.Resizing(64, 64), \n",
    "        tf.keras.layers.Normalization(), \n",
    "          \n",
    "        tf.keras.layers.Conv2D(64, 3, activation='relu'), \n",
    "        tf.keras.layers.Conv2D(128, 3, activation='relu'), \n",
    "        tf.keras.layers.MaxPooling2D(), \n",
    "        tf.keras.layers.Dropout(0.5), \n",
    "        tf.keras.layers.Flatten(), \n",
    "          \n",
    "        tf.keras.layers.Dense(256, activation='relu'), \n",
    "        tf.keras.layers.Dropout(0.5), \n",
    "          \n",
    "        tf.keras.layers.Dense(num_labels, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile( \n",
    "    optimizer=tf.keras.optimizers.Adam(), \n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "    metrics=['accuracy'] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "verbose = True\n",
    "\n",
    "monitor = 'val_loss'\n",
    "min_delta = 0.01\n",
    "patience = 3\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(monitor=monitor, min_delta=min_delta, patience=patience, verbose=verbose)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 96/140 [===================>..........] - ETA: 3s - loss: 0.5345 - accuracy: 0.8522"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nHeader mismatch: Expected RIFF but found FORM\n\t [[{{node DecodeWav}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_7828]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\interpreter2\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\interpreter2\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nHeader mismatch: Expected RIFF but found FORM\n\t [[{{node DecodeWav}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_7828]"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_set,\n",
    "    validation_data=val_set,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpreter2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
